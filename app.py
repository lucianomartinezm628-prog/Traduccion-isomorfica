import streamlit as st
import google.generativeai as genai
import time
from google.api_core import exceptions

# ==============================================================================
# 1. CONFIGURACI√ìN E INICIALIZACI√ìN
# ==============================================================================
st.set_page_config(
    page_title="Sistema de Traducci√≥n Isom√≥rfica (Chat)",
    page_icon="üõ°Ô∏è",
    layout="wide"
)

# --- TUS PROTOCOLOS EXACTOS (CONSTITUCI√ìN) ---
CONSTITUCION = """
ACT√öA ESTRICTAMENTE BAJO LOS SIGUIENTES PROTOCOLOS. NO TE SALGAS DEL PERSONAJE.
ERES EL SISTEMA DE TRADUCCI√ìN ISOM√ìRFICA. TU √öNICO OBJETIVO ES EJECUTAR ESTAS REGLAS:

‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
PROTOCOLO 0: MODO DE OPERACI√ìN (Flujo e Interacci√≥n)
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
PRINCIPIO FUNDAMENTAL:
  El usuario es la m√°xima autoridad. Ante duda ‚Üí PREGUNTAR.

0.1. FLUJO MACRO
  Input ‚Üí P10.A (Limpieza) ‚Üí P8.A (An√°lisis) ‚Üí [CONSULTA PRE] ‚Üí P3-P7 (Traducci√≥n) ‚Üí [CONSULTA DURANTE] ‚Üí P10.B (Salida).

0.5. FALLO CR√çTICO
  Si detectas: Registro incompleto, Sinonimia en n√∫cleo, o Token no registrado:
  DETENTE INMEDIATAMENTE. Pide intervenci√≥n.

0.13. MODO DE SALIDA
  Por defecto opera en MODO BORRADOR (con marcas de debug si necesario).
  Si el usuario pide MODO FINAL, entrega texto limpio.

‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
PROTOCOLO 1.A: DEFINICIONES ‚Äî Conceptos
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
1.A.2. JERARQU√çA: ESTILO > IDENTIDAD > COHESI√ìN.
  Si el autor es oscuro, la traducci√≥n es oscura.
  
1.A.3. REGLA ETIMOL√ìGICA:
  Si etimolog√≠a ‚â† uso t√©cnico pero met√°fora viable ‚Üí ELEGIR ETIMOLOG√çA.

1.A.4. TOKENS:
  N√öCLEOS (Sust, Verb, Adj, Adv): INVARIABLES (1:1). Sinonimia PROHIBIDA.
  PART√çCULAS (Prep, Conj, Pron): POLIVALENTES (seg√∫n funci√≥n).

‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
PROTOCOLO 2: CONSTITUCI√ìN (Reglas Inviolables)
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
PROHIBIDO:
  - Crear coherencia sin permiso.
  - Reordenar tokens (Isomorfismo posicional estricto).
  - Eliminar tokens (usar {...} para nulidad).
  - Usar sin√≥nimos en n√∫cleos.
  - Traducir componentes de locuciones por separado.

PERMITIDO:
  - Inyecciones [...] para soporte gramatical m√≠nimo (Whitelist P7).
  - Agramaticalidad si proviene del isomorfismo.

‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
PROTOCOLO 3 & 4: CORE Y N√öCLEOS
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
P3: Mantener Size(Mtx_T) == Size(Mtx_S).
P4: Prioridad Etimol√≥gica: LENGUA_FUENTE > LATINA > GRIEGA > √ÅRABE.

‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
PROTOCOLO 8: GLOSARIO
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
A4. VERIFICACI√ìN: Antes de traducir, verifica que cada palabra tenga definici√≥n.
B3. SINONIMIA: Si intentas usar una palabra diferente para un n√∫cleo ya traducido antes -> ALERTA DE ERROR.

‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
PROTOCOLO 9: FORMACI√ìN L√âXICA
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
Si no hay ra√≠z en espa√±ol (NO_ROOT):
  Transliterar + Sufijo Espa√±ol (ej: ma'q√∫l -> ma'qulado).
Si es locuci√≥n (IDIOM):
  Traducir componentes etimol√≥gicamente y unir con guiones (ej: por-ojo-suyo).

‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
PROTOCOLO 11: COMANDOS
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
Reconoce y ejecuta comandos como: [GLOSARIO], [ESTADO], [PAUSA], [FORZAR], [ACTUALIZA x=y].

--- INSTRUCCI√ìN FINAL PARA LA IA ---
1. Analiza el input del usuario.
2. Si es un COMANDO, ejec√∫talo y muestra el resultado.
3. Si es TEXTO A TRADUCIR, aplica el flujo P10->P8->P3...
4. Si encuentras dudas (C1-C6), DETENTE y pregunta usando el FORMATO DE CONSULTA (0.6).
5. NO traduzcas de golpe si hay palabras nuevas; primero presenta el GLOSARIO PRELIMINAR (P8.A) para aprobaci√≥n.
"""

# ==============================================================================
# 2. FUNCIONES AUXILIARES (MANEJO DE ERRORES)
# ==============================================================================

def generar_respuesta_con_retry(model, prompt, chat_history):
    """
    Intenta generar respuesta manejando el error 429 (Cuota excedida)
    con espera exponencial (Backoff).
    """
    max_retries = 3
    base_wait = 10 # Segundos de espera inicial

    for attempt in range(max_retries):
        try:
            # Iniciamos el chat con el historial
            chat = model.start_chat(history=chat_history)
            
            # Devolvemos el generador de respuesta (stream)
            return chat.send_message(prompt, stream=True)

        except exceptions.ResourceExhausted:
            # Error 429: Cuota excedida
            wait_time = base_wait * (attempt + 1)
            msg = f"‚è≥ Tr√°fico alto (Error 429). Reintentando en {wait_time}s... (Intento {attempt+1}/{max_retries})"
            st.toast(msg, icon="‚ö†Ô∏è")
            time.sleep(wait_time)
            continue
        
        except exceptions.NotFound:
             st.error("‚ùå Error 404: El modelo seleccionado no est√° disponible en tu regi√≥n o fue retirado. Cambia el modelo en la barra lateral.")
             return None
             
        except Exception as e:
            st.error(f"‚ùå Error inesperado: {str(e)}")
            return None
    
    st.error("‚õî Se agotaron los intentos. El servicio est√° saturado. Intenta con un modelo 'Lite' o espera un minuto.")
    return None

# ==============================================================================
# 3. INTERFAZ Y L√ìGICA DE CHAT
# ==============================================================================

def main():
    # --- Sidebar ---
    with st.sidebar:
        st.header("‚öôÔ∏è Configuraci√≥n P0")
        api_key = st.text_input("Gemini API Key", type="password")
        
        # LISTA ESTRICTA DE TUS MODELOS COMPATIBLES
        # Se pone primero el m√°s seguro (Latest)
        modelos_disponibles = [
            "gemini-flash-latest",          # Alias seguro (suele ser 1.5 o 2.0 estable)
            "gemini-flash-lite-latest",     # Alias ligero seguro
            "gemini-2.0-flash-lite",        # R√°pido, propenso a 429 en free tier
            "gemini-2.0-flash",             # Potente, propenso a 429
            "gemini-2.5-flash-lite",        # Preview
            "gemini-2.5-flash",             # Preview
            "gemini-pro-latest",
            "gemma-3-27b-it"                # Modelo abierto servido por API
        ]
        
        modelo = st.selectbox(
            "Modelo Activo", 
            modelos_disponibles, 
            index=0,
            help="Si recibes errores de 'Quota exceeded', prueba con 'flash-latest' o 'lite'."
        )
        
        st.divider()
        st.info("Sistema cargado con Protocolos P0-P11.")
        
        if st.button("üóëÔ∏è Reiniciar Sesi√≥n"):
            st.session_state.messages = []
            st.rerun()

    st.title("üõ°Ô∏è Sistema de Traducci√≥n Isom√≥rfica")
    st.caption(f"Operando con: **{modelo}** | Temperatura: 0.0 (Estricta)")

    # --- Inicializar Historial ---
    if "messages" not in st.session_state:
        st.session_state.messages = [
            {"role": "assistant", "content": "Sistema P0 Iniciado. Protocolos cargados. Esperando Input o Comandos (ej: [GLOSARIO], [ESTADO])."}
        ]

    # --- Mostrar Historial ---
    for msg in st.session_state.messages:
        with st.chat_message(msg["role"]):
            st.markdown(msg["content"])

    # --- Capturar Input del Usuario ---
    if prompt := st.chat_input("Escribe texto para traducir o comando..."):
        
        if not api_key:
            st.error("‚ö†Ô∏è Por favor ingresa tu API Key en la barra lateral.")
            return

        # 1. Guardar mensaje usuario
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)

        # 2. Llamar a Gemini
        genai.configure(api_key=api_key)
        
        # Configuraci√≥n ESTRICTA
        generation_config = {
            "temperature": 0.0,
            "top_p": 1,
            "top_k": 1,
            "max_output_tokens": 8192,
        }

        try:
            model_instance = genai.GenerativeModel(
                model_name=modelo,
                system_instruction=CONSTITUCION,
                generation_config=generation_config
            )

            # Preparar historial para la API
            chat_history_api = []
            for m in st.session_state.messages[:-1]: # Excluir el √∫ltimo prompt que ya enviamos
                role = "user" if m["role"] == "user" else "model"
                chat_history_api.append({"role": role, "parts": [m["content"]]})

            # Generar respuesta (Con reintentos)
            with st.chat_message("assistant"):
                response_placeholder = st.empty()
                full_response = ""
                
                # Llamada segura con retry
                response_stream = generar_respuesta_con_retry(model_instance, prompt, chat_history_api)
                
                if response_stream:
                    try:
                        for chunk in response_stream:
                            if chunk.text:
                                full_response += chunk.text
                                response_placeholder.markdown(full_response + "‚ñå")
                        
                        response_placeholder.markdown(full_response)
                        
                        # 3. Guardar respuesta asistente solo si hubo √©xito
                        st.session_state.messages.append({"role": "assistant", "content": full_response})
                    except Exception as stream_err:
                        st.error(f"Error procesando respuesta: {stream_err}")

        except Exception as e:
            st.error(f"Error de Configuraci√≥n: {str(e)}")

if __name__ == "__main__":
    main()
